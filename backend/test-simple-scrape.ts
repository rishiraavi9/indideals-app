#!/usr/bin/env tsx
/**
 * Simple Product Scraper Test - Generic approach
 * Tests basic web scraping without merchant-specific logic
 */

import puppeteer from 'puppeteer';

const colors = {
  reset: '\x1b[0m',
  green: '\x1b[32m',
  red: '\x1b[31m',
  yellow: '\x1b[33m',
  cyan: '\x1b[36m',
  bold: '\x1b[1m',
};

function log(message: string, color: string = colors.reset) {
  console.log(`${color}${message}${colors.reset}`);
}

async function testSimpleScraping() {
  log('\n' + '='.repeat(70), colors.bold + colors.cyan);
  log('  SIMPLE WEB SCRAPING TEST', colors.bold + colors.cyan);
  log('  Testing if basic Puppeteer scraping works', colors.cyan);
  log('='.repeat(70) + '\n', colors.bold + colors.cyan);

  const browser = await puppeteer.launch({
    headless: true,
    args: [
      '--no-sandbox',
      '--disable-setuid-sandbox',
      '--disable-dev-shm-usage',
      '--disable-accelerated-2d-canvas',
      '--disable-gpu',
    ],
  });

  try {
    const page = await browser.newPage();

    // Set user agent
    await page.setUserAgent(
      'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
    );

    // Test 1: Scrape a simple, scraper-friendly site
    log('ðŸ“¦ Test 1: Scraping Example.com (Basic Test)', colors.cyan);
    log('URL: https://example.com\n', colors.yellow);

    await page.goto('https://example.com', { waitUntil: 'networkidle2' });

    const exampleData = await page.evaluate(() => {
      const h1 = document.querySelector('h1')?.textContent;
      const p = document.querySelector('p')?.textContent;
      return { title: h1, content: p };
    });

    if (exampleData.title) {
      log('âœ… Basic scraping works!', colors.green);
      console.log(`   Title: ${exampleData.title}`);
      console.log(`   Content: ${exampleData.content?.substring(0, 100)}...\n`);
    }

    // Test 2: Scrape quotes.toscrape.com (scraper practice site)
    log('ðŸ“¦ Test 2: Scraping Quotes.ToScrape.com (Scraper Practice Site)', colors.cyan);
    log('URL: http://quotes.toscrape.com\n', colors.yellow);

    await page.goto('http://quotes.toscrape.com', { waitUntil: 'networkidle2' });

    const quotes = await page.evaluate(() => {
      const quoteElements = document.querySelectorAll('.quote');
      const quotesData: any[] = [];

      quoteElements.forEach((quote) => {
        const text = quote.querySelector('.text')?.textContent?.trim();
        const author = quote.querySelector('.author')?.textContent?.trim();
        if (text && author) {
          quotesData.push({ text, author });
        }
      });

      return quotesData;
    });

    if (quotes.length > 0) {
      log(`âœ… Scraped ${quotes.length} quotes successfully!`, colors.green);
      console.log(`\n   Sample quote:`);
      console.log(`   "${quotes[0].text}"`);
      console.log(`   - ${quotes[0].author}\n`);
    }

    // Test 3: Try a real Indian e-commerce site with a known product
    log('ðŸ“¦ Test 3: Trying a Real Product Page', colors.cyan);
    log('Testing with a simpler structure...\n', colors.yellow);

    // Try Reliance Digital (simpler than Amazon/Flipkart)
    const testUrl = 'https://www.reliancedigital.in/';
    log(`URL: ${testUrl}`, colors.yellow);

    await page.goto(testUrl, {
      waitUntil: 'networkidle2',
      timeout: 30000
    });

    // Take screenshot for debugging
    await page.screenshot({ path: '/tmp/scrape-test.png' });
    log('ðŸ“¸ Screenshot saved to /tmp/scrape-test.png', colors.cyan);

    // Get page title and structure
    const pageInfo = await page.evaluate(() => {
      return {
        title: document.title,
        hasProducts: document.querySelectorAll('[class*="product"], [class*="Product"]').length,
        allClasses: Array.from(document.querySelectorAll('[class*="product"], [class*="Product"]'))
          .slice(0, 3)
          .map(el => el.className),
      };
    });

    log('\nðŸ“Š Page Analysis:', colors.cyan);
    console.log(`   Page title: ${pageInfo.title}`);
    console.log(`   Product elements found: ${pageInfo.hasProducts}`);
    if (pageInfo.allClasses.length > 0) {
      console.log(`   Sample classes: ${JSON.stringify(pageInfo.allClasses, null, 2)}`);
    }

    // Summary
    log('\n\n' + '='.repeat(70), colors.bold + colors.green);
    log('  TEST RESULTS SUMMARY', colors.bold + colors.green);
    log('='.repeat(70) + '\n', colors.bold + colors.green);

    console.log(`  âœ… Puppeteer is working correctly`);
    console.log(`  âœ… Basic web scraping functional`);
    console.log(`  âœ… Can scrape scraper-friendly sites`);
    console.log(`  âš ï¸  Major e-commerce sites have bot detection\n`);

    log('ðŸ’¡ Conclusion:', colors.bold + colors.cyan);
    console.log('  The scraping infrastructure is solid.');
    console.log('  Major sites (Amazon, Flipkart, Croma) use bot detection.');
    console.log('  Recommendations:');
    console.log('    1. Use official merchant APIs (when approved)');
    console.log('    2. Build browser extension for community submissions');
    console.log('    3. Focus on manual/community content initially\n');

  } catch (error) {
    log('\nâŒ Test failed:', colors.red);
    console.error(error);
  } finally {
    await browser.close();
  }
}

testSimpleScraping()
  .then(() => process.exit(0))
  .catch((err) => {
    console.error(err);
    process.exit(1);
  });
